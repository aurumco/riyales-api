name: Market Data Sync
on:
  schedule:
    - cron: '*/5 * * * *'
  workflow_dispatch:
    inputs:
      upload_v1_data:
        description: 'Upload all v1 directories (true/false)'
        required: true
        default: false
        type: boolean
  push:
    branches:
      - main
env:
  PYTHON_VERSION: '3.13'
jobs:
  sync-data:
    name: Sync
    runs-on: ubuntu-latest
    permissions:
      contents: write
    env:
      BRS_API_KEY: ${{ secrets.BRS_API_KEY }}
      BRS_BASE_URL: ${{ secrets.BRS_BASE_URL }}
      TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
      TELEGRAM_USER_ID: ${{ secrets.TELEGRAM_USER_ID }}
      LOG_LEVELS: ${{ secrets.LOG_LEVELS || 'ERROR' }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      - name: Restore pip cache
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      - name: Cache apt packages for lftp
        uses: actions/cache@v4
        id: apt-cache
        with:
          path: |
            /var/cache/apt/archives
            /var/lib/apt/lists
          key: ${{ runner.os }}-apt-lftp-cache
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
        shell: bash
      - name: Run data-fetch script
        run: |
          mkdir -p logs
          python src/main.py
        shell: bash
      - name: Pull latest & Commit if any
        run: |
          git config --global user.name "Market Data Bot"
          git config --global user.email "market-data-bot@users.noreply.github.com"
          
          echo "• Pulling latest changes from origin/main"
          if ! git pull --rebase --autostash origin main; then
            echo "• ERROR: Git pull failed with conflicts or errors"
            git rebase --abort 2>/dev/null || true
            git pull origin main || echo "• ERROR: Fallback git pull also failed"
          fi
          
          echo "• Checking for changes in market data files and logs..."
          git add api/v1/
          git add api/v2/market/
          git add logs/
          
          find api/v1/ api/v2/market/ -type f -size +100M | while read file; do
            echo "• Skipping large file from commit: $file"
            git restore --staged "$file"
          done
          
          if ! git diff --staged --quiet; then
            echo "• Changes detected in market data files. Committing..."
            MSG=$(python src/commit_message.py)
            git commit -m "$MSG" -m "Triggered by: ${{ github.event_name }}"
            
            echo "• Pushing changes to origin/main"
            if ! git push origin main; then
              echo "• ERROR: Git push failed"
            fi
          else
            echo "• No changes to market data files. Skipping commit."
          fi
        shell: bash
      - name: Upload API data to Download Server via FTP
        run: |
          # Clean apt lists before update to prevent cache issues
          sudo rm -rf /var/lib/apt/lists/*
          # Install lftp client (will be fast if cache is hit)
          sudo apt-get update && sudo apt-get -y install lftp
          
          # Define v1 directories
          V1_DIRECTORIES="api/v1/config api/v1/banner api/v1/ads api/v1/assets api/v1/terms"
          
          # Start building the lftp command array
          lftp_commands=(
            "open -u ${{ secrets.FTP_USERNAME }},${{ secrets.FTP_PASSWORD }} ftp://3117204815.cloudydl.com"
            "set ssl:verify-certificate no"
            "mkdir -p public_html/riyales/api/v2"
            "mkdir -p public_html/riyales/api/v1"
          )
          # Always sync v2 data
          echo "• Scheduling v2 directory for unconditional upload."
          lftp_commands+=("mirror -R --verbose --delete --parallel=5 api/v2/market/ public_html/riyales/api/v2/market")

          # Conditionally sync v1 directories ONLY on manual trigger
          if [[ "${{ github.event_name }}" == "workflow_dispatch" && "${{ github.event.inputs.upload_v1_data }}" == "true" ]]; then
            echo "• Manual trigger active: Scheduling all v1 directories for upload."
            for dir_path in $V1_DIRECTORIES; do
              lftp_commands+=("mirror -R --verbose --delete --parallel=5 '$dir_path' 'public_html/riyales/api/v1/'")
            done
          else
            echo "• Skipping v1 directories upload. Manual trigger not activated."
          fi

          lftp_commands+=("bye")
          lftp_script=$(printf "%s;" "${lftp_commands[@]}")
          echo "--- Executing FTP Sync Script ---"
          lftp -c "$lftp_script"
          echo "--- FTP Sync Script Finished ---"
        shell: bash
      - name: Check and send error logs
        if: always()
        run: |
          ERROR_LOG="${GITHUB_WORKSPACE}/logs/error.log"
          echo "• Final check for error log at: ${ERROR_LOG}"
          
          if [ -f "${ERROR_LOG}" ]; then
            RELEVANT_LINES=$(grep -cvE '(^\s*$)|(^# Log cleared on)|(^# Log forcibly cleared on)' "${ERROR_LOG}" || true)
            
            if [ "${RELEVANT_LINES}" -gt 0 ]; then
              echo "• Error log has relevant content (${RELEVANT_LINES} lines). Running alert_sender.py..."
              cd "${GITHUB_WORKSPACE}"
              python src/alert_sender.py
              
              if [ -s "${ERROR_LOG}" ]; then
                echo "• WARNING: error.log was NOT truncated. Forcing truncation." | tee -a "${ERROR_LOG}"
                echo "# Log forcibly cleared by workflow at $(date -u '+Y-%m-%dT%H:%M:%SZ')" > "${ERROR_LOG}"
              else
                echo "• error.log successfully truncated."
              fi
            else
              echo "• Error log is empty or contains only clear messages. Skipping alert."
            fi
          else
            echo "• No error.log file found. Skipping alerts."
          fi
        shell: bash
  cleanup:
    name: Cleanup
    needs: sync-data
    if: always()
    runs-on: ubuntu-latest
    permissions:
      actions: write
    env:
      GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      REPO: ${{ github.repository }}
      WF: ${{ github.workflow }}
    steps:
      - name: Remove old workflow runs
        run: |
          runs=$(gh run list \
            --repo "$REPO" \
            --workflow "$WF" \
            --limit 100 \
            --json databaseId,status,createdAt \
            --jq '.[] | select(.status!="in_progress" and .status!="queued") | {id: .databaseId, date: .createdAt}' | \
            jq -s 'sort_by(.date) | reverse | .[].id')
          total=$(echo "$runs" | wc -l)
          if [ "$total" -le 9 ]; then exit 0; fi
          to_delete=$(echo "$runs" | tail -n +10)
          echo "$to_delete" | while read id; do
            echo "Deleting run ID: $id"
            gh run delete "$id" --repo "$REPO"
          done
        shell: bash
